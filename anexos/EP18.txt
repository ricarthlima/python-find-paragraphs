The current issue and full text archive of this journal is available on Emerald Insight at:
www.emeraldinsight.com/2056-4961.htm

Socio-technical systems
cybersecurity framework

Cybersecurity
framework

Masike Malatji
Postgraduate School of Engineering Management, University of Johannesburg,
Johannesburg, South Africa

Sune Von Solms
Department of Electrical Engineering Science, University of Johannesburg,
Johannesburg, South Africa, and

233
Received 19 March 2018
Revised 7 August 2018
10 October 2018
Accepted 1 November 2018

Annlizé Marnewick
Postgraduate School of Engineering Management, University of Johannesburg,
Johannesburg, South Africa

Abstract
Purpose – This paper aims to identify and appropriately respond to any socio-technical gaps within
organisational information and cybersecurity practices. This culminates in the equal emphasis of both the
social, technical and environmental factors affecting security practices.
Design/methodology/approach – The socio-technical systems theory was used to develop a conceptual
process model for analysing organisational practices in terms of their social, technical and environmental
inﬂuence. The conceptual process model was then applied to speciﬁcally analyse some selected information
and cybersecurity frameworks. The outcome of this exercise culminated in the design of a socio-technical
systems cybersecurity framework that can be applied to any new or existing information and cybersecurity
solutions in the organisation. A framework parameter to help continuously monitor the mutual alignment of
the social, technical and environmental dimensions of the socio-technical systems cybersecurity framework
was also introduced.
Findings – The results indicate a positive application of the socio-technical systems theory to the
information and cybersecurity domain. In particular, the application of the conceptual process model is able to
successfully categorise the selected information and cybersecurity practices into either social, technical or
environmental practices. However, the validation of the socio-technical systems cybersecurity framework
requires time and continuous monitoring in a real-life environment.
Practical implications – This research is beneﬁcial to chief security ofﬁcers, risk managers, information
technology managers, security professionals and academics. They will gain more knowledge and understanding
about the need to highlight the equal importance of both the social, technical and environmental dimensions of
information and cybersecurity. Further, the less emphasised dimension is posited to open an equal but mutual
security vulnerability gap as the more emphasised dimension. Both dimensions must, therefore, equally and
jointly be emphasised for optimal security performance in the organisation.
Originality/value – The application of socio-technical systems theory to the information and cybersecurity
domain has not received much attention. In this regard, the research adds value to the information and
cybersecurity studies where too much emphasis is placed on security software and hardware capabilities.

Keywords Information security, Security, Modelling
Paper type Research paper

1. Introduction
Malicious software exploits target all sorts of network- and Internet-enabled systems such
as personal devices and critical infrastructure systems to infect, damage or control the

Information & Computer Security
Vol. 27 No. 2, 2019
pp. 233-272
© Emerald Publishing Limited
2056-4961
DOI 10.1108/ICS-03-2018-0031

ICS
27,2

234

systems (Van Heerden et al., 2016). According to Al-Daraiseh et al. (2014), such cyber-crime
is also on the increase. Cyber-crime includes ﬁnancial fraud, stalking and blackmail
(Guitton, 2013). It is thus critical to have a better understanding of relationships between
technical systems and the humans who operate them as far as organisational security is
concerned (Baxter and Sommerville, 2011). Systems can assume different computing
formations, for example industrial control systems, weapons systems, or command, control
and communication systems (Ross et al., 2016). As the National Institute of Standards and
Technology (NIST) (2017a) observes, the commonality in the computing formations is that
they all contain systems with complex ﬁrmware and software. Security of information in
such systems is considered by Craigen et al. (2014) as the gathering and conﬁguration of
enterprise resources, processes and structures against malicious attacks. To adequately
secure systems and monitor their readiness to withstand a barrage of attacks, organisations
need a common framework in addition to standard controls (NIST, 2017b). Friedberg et al.
(2017) argue that the implementation of such a framework should be preceded by a
comprehensive analysis of security vulnerabilities and their probable impact. However, the
authors caution that performing a complete security vulnerability analysis of complex
systems such as an electricity grid is very complicated and completeness is hard to prove.
Moreover, because each organisation’s security risks are different, the tools and techniques
required to achieve security outcomes will also differ (Dasso et al., 2016).
From the above arguments, it is quite evident that modern systems present even greater
vulnerability challenges (Wurm et al., 2017). Examples of some of the world’s most notable
information and cybersecurity vulnerability exploitations include the following:
 In 2010, hackers designed the Stuxnet virus that manipulated Siemens’ industrial
control systems to spin the centrifuges of Iran’s uranium enrichment plant to
overheat (Kenney, 2015).
 In 2015, hackers managed to break into the air-trafﬁc control systems of the United
States (Hu et al., 2016).
 In 2016, cyberattacks cost United Kingdom businesses approximately £30bn. As an
example, the Mirai botnet affected almost 2 500 TalkTalk routers across the United
Kingdom and took 900 000 Deutsche Telekom, Germany, customers ofﬂine (Russel,
2017).
 In 2017, the WannaCry ransomware (also going by the WanaCrypt0r or
WannaCrypt names) infected no less than 200 000 computers across 150 countries
(Furnell and Emm, 2017).
To address these types of information and cybersecurity threats, a security framework is
required to provide a common method to measure cybersecurity capabilities within an
organisation (Le and Hoang, 2016). The metrics of such a framework should include a
capability maturity model that incorporates not only the technical but also the social
dimension of security (Carcary et al., 2016). This will enable the alignment of both the social
and technical dimensions of a system and forms the fundamental tenet of socio-technical
systems theory (Mumford, 2006). According to Whitworth (2009), the misalignment between
the social and technical dimensions of a system is referred to as the socio-technical gap. In
general, socio-technical systems (STS) theory is about an approach that seeks to optimise
the alignment and correlation between the social and technical dimensions of a system,
while considering the system’s environment (Beekun, 1989). Organisations can themselves
be thought of as complex socio-technical systems (Davis et al., 2014). Indeed, Bella et al.
(2015) afﬁrm that organisations comprise not only the software and hardware processes, but

also people, physical objects and geographies. The main objective of this research is
therefore:
 to develop a socio-technical systems framework to help identify and appropriately
respond to any vulnerabilities that may result from the socio-technical gaps within
the existing information and cybersecurity solutions

Cybersecurity
framework

This paper is organised into six main sections. Section 1 contains this introduction and
research objectives. In Section 2 the research approach used for the development of the
socio-technical systems cybersecurity framework is outlined. The review of the sociotechnical systems theory and the analysis of the information and cybersecurity frameworks
are performed in Section 3. In addition, the socio-technical systems theory process model is
developed in Section 3. The design and validation of the socio-technical systems
cybersecurity conceptual framework is described in Section 4. In Section 5 the sociotechnical gaps in the existing information and cybersecurity frameworks are discussed.
Section 5 further recommends clear application and implementation approaches of the
conceptual framework as well as suggestions on future research. The paper concludes with
Section 6.

235

2. Framework development method
The nature and design of the proposed information and cybersecurity framework is based
on the literature of the socio-technical systems theory. Figure 1 illustrates the research
approach adopted in the study. As shown in the socio-technical systems cybersecurity
framework (STS-CF) development methodology in Figure 1, the study demonstrates how an
organisation can generate its joint optimisation security controls.
Joint optimisation simply refers to the best of both the technical and human aspects of
security with equal emphasis (Emery, 1982; Mumford, 2006). The generation of the joint
optimisation security controls is accomplished by analysing the existing information and
cybersecurity practices within the organisation whilst at the same time categorising each
output control as either social, technical or environmental. Where a security solution is
found to place too much emphasis (on either the social or technical), a socio-technical gap is
said to exist. The study sought to design a framework model that could help organisations
attain joint optimisation by identifying and closing socio-technical gaps. These gaps equate
to systems vulnerabilities that are susceptible to exploitation by cyber-attackers. At the
heart of the framework is the joint optimisation process model used to analyse and
1

2

Analyse STS theory
and develop joint optimisation
process

6

3

Analyse conventional information
and cybersecurity controls through
joint optimisation process

5

Validate
STS-CF

Generate STS information
and cybersecurity controls

4

Design STS-CF
using controls and
maturity indicator model

Develop maturity indicator model
for the STS information and
cybersecurity controls

Figure 1.
STS-CF development
methodology

ICS
27,2

236

categorise the existing information and cybersecurity controls. The technique used to
validate the joint optimisation process model involved engagement with two industry
experts. One is a cybersecurity strategist and the other a security employee within an
information technology (IT) department of an organisation. The two experts were
independently taken through the concept of socio-technical systems wherein a distinction
between the social, technical and environmental attributes was made. Thereafter, they were
asked to independently examine the information and cybersecurity framework controls, as
listed in Appendix A, and classify them into either the social, technical or environmental
dimension.
The approach in Figure 1 consists of the following steps:
 Analyse STS theory and develop joint optimisation process. The socio-technical
systems theory is reviewed and a high-level theoretical framework emphasising
equal attention to both the social and technical dimensions is conceptualised. This is
called the joint optimisation process.
 Analyse information and cybersecurity controls through the joint optimisation
process. Although it is acknowledged that this is not an exhaustive list, the analysed
controls were extracted from frequently published and industry-recognised
information and cybersecurity frameworks between 2001 and 2017. This is because
those frameworks will have had sufﬁcient time to be tested and validated. An
equally signiﬁcant criteria is that whether these frameworks are industry-speciﬁc,
governance-, risk- or even compliance-based, they must strictly have aspects of
information security. Upon analysis, the purely techno-centric frameworks are
regarded as having failed the joint optimisation process. That is, the socio-technical
gap for justifying this research will have been found.
 Generate STS cybersecurity controls. Security controls analysed and iteratively
passed through the joint optimisation process are compiled. In addition, duplicate
controls are eliminated and similar ones combined. This culminates into new and
adaptable high-level STS information and cybersecurity controls.
 Develop STS cybersecurity controls maturity indicator model. To measure the degree
to which the implemented information and cybersecurity controls mature, an
appropriate capability maturity model is developed.
 Develop the STS-CF. Together with the joint optimisation process, the generated
security controls and capability maturity model are combined to form a conceptual
STS cybersecurity framework.
 Validate the STS-CF. To provide proof of concept, the researchers plan to implement
the proposed STS-CF in one or two organisations in South Africa to test its validity
and usefulness. The results thereof will be discussed in the subsequent publication.
The next section discusses how Steps 1 through 4 are executed through the application of
the socio-technical systems theory to the information and cybersecurity domain.
3. Literature review
3.1 Socio-technical systems theory
3.1.1 Concept discussion. The STS theory is ﬁrst analysed in this subsection. First coined by
Emery and Trist, a classical socio-technical systems theory is a combination of the social
and technical dimensions that are susceptible to their operating environments (Appelbaum,
1997). Socio-technical systems are distinguished by a high level of social intricacy and

technical complexities intended to fulﬁl society’s important functions (Baxter and
Sommerville, 2011; Wu et al., 2015). They are the synergistic union of people, technology,
organisational structures and processes, including the operating environment within which
all these occur (Carayon et al., 2015). In its modern holistic view, Whitworth (2009) adds that
a socio-technical system is not one of two separate and side-by-side systems, but the whole
integrated system. It is the interaction between the social (including how teams and
individual team members perform tasks) and technical systems (including complex
interdependencies of the system development life cycle) (Troyer, 2017). Perhaps a more
concise description is provided by Bostrom and Heinen (1977), and Walker et al. (2007), that
STS are made up of humans applying technology solutions to execute work activities
through processes within a social structure (organisation) to accomplish set goals. It should
be noted that the social dimension is equally, if not more, complex even at smaller levels of
groupings of people (Troyer, 2017). On the one hand, Appelbaum (1997) and Egan et al.
(2004) argue that the main aim of the social dimension is to design work structures that
respond to the psychological needs of the employees including taking on meaningful tasks
and a sense of belonging and responsibility. On the other hand, the technical dimension is
mainly concerned with the provision of tools and techniques used to accomplish
organisational goals (Appelbaum, 1997; Egan et al., 2004).
In this regard, improving one dimension of a socio-technical system requires an
improvement of the other for maintaining the best performance (Trist, 1981). As previously
alluded to, this is called joint optimisation (Bostrom and Heinen, 1977; Appelbaum, 1997;
Walker et al., 2007; Carayon et al., 2015; Oosthuizen and Pretorius, 2016). Joint optimisation
is the cornerstone and foundation of the socio-technical systems theory (Chen and Redar,
2014). Although exclusively optimising either the social or technical dimension of an
organisation will result in performance improvement in that speciﬁc area, researchers agree
that this might lead to an overall sub-optimal STS performance (Washington and Hacker,
2000). Thus, a STS approach is more concerned with harnessing the best of both the
technical and human aspects of organisational performance to accomplish the joint
optimisation state (Emery, 1982; Mumford, 2006). Where the joint optimisation state lacks, a
socio-technical gap exists as shown in Figure 2.
Troyer (2017) has cautioned that in reality, though, the relationships between people,
processes and technology is more often non-linear (complex), recursive and difﬁcult to
predict. What is not in doubt is that the STS theory represents a unique approach relating to

Cybersecurity
framework

237

Technical gap
p

Social
Technical
dimension
dimension

Social
Technical
a dimension
dimension

Social gap

Figure 2.
Socio-technical gap,
derived from
Whitworth (2009)

ICS
27,2

238

the interrelatedness of social and technical dimensions of an organisation (Walker et al.,
2007). Regardless of the complexity of organisations as complex technical and social
systems, the STS theory provides a robust framework for analysis (Troyer, 2017).
Oosthuizen and Pretorius (2016) agree that the STS theory can provide a good framework
for modelling organisations as complex systems. Bostrom and Heinen (1977) argue that, on
the one hand, the social dimension consists of:
 organisational structure; and
 actors (including people).
The technical dimension, on the other hand, comprises:
 technology; and
 work activities (tasks).
Table I serves as a guideline to conceptually develop the relevant attributes for both the
social and technical dimensions of a socio-technical system within a complex environment.
Table I shows that:
 Organisational structure constitute the social dimension enable systems of
authority, communication and work ﬂow (Hester, 2014).
 Actors are all the members of an organisation as a complex STS, including the main
stakeholders who inﬂuence or perform work activities (Hester, 2014).

Social
dimension

Table I.
Social and technical
dimensions
attributes

Attributes

Technical
dimension

Organisational structure
(functions)

Skill/ability
Values and norms
Patterns of behaviour
Culture
Knowledge
reporting/authority
Structures and control
Reward systems
Coordination needs
Policy

Technology
(tools/resources)

Actors
(human beings)

Individuals/people/humans
Teams/work groups
People relations

Work activities
(tasks)

Environmental
Legal
Geographical locations
Natural disasters

Built environment
Physical environment
Suppliers
Customers

Environmental dimension
Political
Economic
Social
Technological

Attributes
Technology
Hardware
Software
Equipment
Machines
Tools
Physical security
Cybersecurity
Built environment
Information
Processes
Procedures
Techniques
Activity tasks
Work organisations

Government
Other external
entities

Sources: (Bostrom and heinen, 1977; Trist, 1981; Washington and hacker, 2000; Mumford, 2006; Davis
et al., 2014; Hester, 2014; Wu et al., 2015; Oosthuizen and pretorius, 2016; Schuetz and Schreﬂ, 2017)



Technology provides the tools and resources used in carrying out work activities
(tasks) (Hester, 2014).
Work activities are carried out within social infrastructures (Wu et al., 2015), which
encompass government regulations and ‘organisational structures’ (Davis et al.,
2014).

Cybersecurity
framework

As already alluded to by Appelbaum (1997) and Carayon et al. (2015), an organisation, as a
complex socio-technical system, is susceptible to the inﬂuence of the external environment it
is embedded in (Chen and Redar, 2014). For example, a particular regulatory framework by
government may greatly affect certain organisational goals (Davis et al., 2014). Table I
shows attributes of the environmental dimension that can inﬂuence both the social and
technical security attributes of an organisation. The environmental dimension therefore
refers to the factors inﬂuencing and impacting upon a system (social and technical parts)
(Appelbaum, 1997). The environmental dimension cuts-across both the social and technical
dimensions.
On the one hand, there are complex political, economic, social, technological,
environmental and legal factors (Schuetz and Schreﬂ, 2017). On the other hand, the built
environment, physical environment, geographical locations and natural disasters also
constitute complex environmental factors (Wu et al., 2015). To summarise Table I, human
beings perform tasks using tools and resources for a speciﬁc function. Therefore, if human
beings are not adequately resourced, the functions will not be performed optimally.
Similarly, if the available tools and resources are in abundance but the people who use them
are not adequately skilled, the functions will not be performed optimally. The entire STS
must be balanced for optimal performance.
STS methods are not without criticism though. According to Mumford (2006), the failure
to adopt and maintain the usage of STS approaches in, for example, the design of complex
organisational systems which currently rely heavily on software-intensive systems
emanates from a few challenges that must be overcome. Some of these challenges include
inconsistent usage of STS terminology, perceived anachronism and analysis without
synthesis (Baxter and Sommerville, 2011; Wu et al., 2015). Although the underlying STS
philosophy has remained largely unchanged over the years, the speciﬁc applications and
general principles have evolved over time to reﬂect the changing nature of technology and
work practices (Davis et al., 2014). This is in contrast to Baxter and Sommerville’s (2011)
argument about the perceived STS theory anachronism (failure to keep up with technology
trends and organisational developments). Regardless, some of the many different
applications of STS thinking already include the economic, legal and regulatory, technical
and security focus areas (Wu et al., 2015). Probably the most popular application of STS
theory has been the development of self-regulating work groups (Appelbaum, 1997).
However, the STS approach recognises the signiﬁcance, as well as limitations, of group
dynamics and the need to identify the complex interdependencies between the social and
technical dimensions (Walker et al., 2007). In this regard, the application of the joint
optimisation concept can help emphasise the signiﬁcance of all the STS dimensions working
in concert (Chen and Redar, 2014).
3.1.2 Application of socio-technical systems theory. Section 1 introduced some of the
world’s most recent cyber-attacks. Table II contains some of the methods adopted by cyberattackers when pursuing a target. These cyber-attack methods are primarily concerned with
access to, and compromise of, organisational information and data by unauthorised users.
Being socio-technical in nature, successful information systems security design is dependent
on two dimensions: humans and technology (Sabbagh and Kowalski, 2012).

239



ICS
27,2

240

Table II.
Information and
cybersecurity
threats, derived from
jing et al. (2014),
soomro et al., 2015,
Dellios et al. (2015),
ray et al. (2016),
puthal et al. (2016),
budzak (2016),
laybats and
tredinnick (2016) and
vuorinen and tetri
(2016)

Figure 3.
Information system
as a socio-technical
system, derived from
Whitworth (2009)

Together with the social and technical dimensions shown in Table I, the humans and
technology pillars are part of a four-layer information systems structure such as that in
Figure 3 (Whitworth, 2009). If the top two layers are together considered social, and the
bottom two technical, then (socio-technical) information systems involve all four layers.
Baxter and Sommerville (2011) recommend that organisations adopt this type of STS
approach to reduce the risk of systems failure. Therefore, it would be highly ineffective to
simply deploy new information systems within a hierarchical control system without
acknowledging the human advantages and social limitations (Walker et al., 2007). That is,
the introduction of change to one part of the STS without considering how this might affect
the other dimensions of a system will limit overall effectiveness (Davis et al., 2014).

Information and cybersecurity attack types
Tampering
Sensor device capture
Fake device and
malicious data
Sybil attack
Source device
authentication problem
Implicit deduction from
sensing behaviours
Encryption leakage
Side channel attack
Insecure Web interface

Jamming
Timing attack
Replay attack
Routing threats
Hardware Trojan
Illegal hardware clones
A denial-of-service
attack
Collision
Insecure cloud interface
Poor physical security
Insecure mobile
interface

Selective forwarding
Wormhole attack
Hello ﬂood
Spooﬁng and
alternating routing
information
Man-in-the-middle
attacks
Insufﬁcient security
conﬁgurability
Insecure software/
ﬁrmware

Authentication concerns
Data protection and
recovery
Inability to deal with big
data
Application layer
software vulnerabilities
Data availability attacks
Lack of transport
encryption
Privacy concerns
Insecure network services
Insufﬁcient authentication
and authorisation

Put differently, emphasising the technical side of a socio-technical system by investing more
in its practices and neglecting the social dimension, or vice versa, will not automatically
translate into the optimal performance of a system (Hadid et al., 2016). This is because a
socio-technical system, at least in its modern holistic view, is the entire system and not one
of the dimensions of the system. Walker et al. (2007), Davis et al. (2014) and Hadid et al.
(2016) all agree that optimisation of each socio-technical system element alone tends to
increase not only the number of unpredictable relationships, but also the kind that
negatively affects the overall system performance. Perhaps this explains why information
and cybersecurity attacks have recently become increasingly successful – the existing
information security practices are too technocentric (Davis et al., 2014). If the STS
approaches are to be successful, however, Baxter and Sommerville (2011) caution that they
must be compatible with and preserve the existing technocentric methods. In this regard,
this research does not propose a stand-alone STS cybersecurity framework solution. Rather,
a socio-technical systems cybersecurity framework that should be used in addition to, or in
conjunction with, any industry-recognised information and cybersecurity framework is
proposed. A number of methods applying the STS theory have been developed over the
years as shown in Table III (Davis et al., 2014).
A comprehensive review of these methods serves to generate valuable insight that can
lead to innovative methods for improving security (Carayon et al., 2015). The analyses of
most of the STS models in Table III were performed by Underwood and Waterson (2012),
Carayon et al. (2015) and Wu et al. (2015). It is apparent from their reviews that the vast
majority of the STS approaches have been applied to the analyses of accidents and
workplace safety (Wiegmann and Shappell, 2003; Underwood and Waterson, 2012; Leveson,
2004). Examples of the accidents and workplace safety models include the systems theoretic
accident modelling and processes, AcciMap and human factors analysis and classiﬁcation
system. In comparison, the functional resonance analysis method appears to be a more
generic than specialised approach. Although the functional resonance analysis method has
also historically been applied to accident analysis activities (Underwood and Waterson,
2012), its developer, Hollnagel (2017) categorically discourages the notion that the functional
resonance analysis method be considered an accident analysis method and/or risk
assessment tool. Instead, Hollnagel (2017) recommends that the model serve as the basis for
risk assessments, incidents and events investigations, or for something completely different
for that matter. However, no formal validity, reliability and usability evaluation of the
functional resonance analysis method has been conducted (Underwood and Waterson,
2012). As a result, the research developed a suitable STS analysis process to help categorise
organisational practices into either social, technical or environmental.
3.1.3 Development of socio-technical systems analysis process. With reference to the STSCF development methodology in Figure 1, Step 1 is completed in this subsection. According
to the Merriam-Webster dictionary, optimisation refers to a methodology, process, or an act
of making something (such as a system, or design) as completely effective, functional, or
perfect as possible. In this regard, the research proposes an analytical tool that will help
identify gaps preventing any socio-technical system from becoming as completely effective,
functional, or perfect as possible. The proposed analytical tool is called the joint
optimisation analysis process as shown in Figure 4.
By using Table I as a guideline, the joint optimisation analysis process is developed and
operationalised as follows:
 gather (social, technical and environmental) data in the organisation;
 facilitate the classiﬁcation of information into either social, technical, or
environmental with participants;

Cybersecurity
framework

241

ICS
27,2

242

STS model

Author/publisher

Year

Purpose

STS theory

Trist and Bamforth
Trist
Mumford

1951
1981
2006

Anthropotechnology

Wisner

1991

AcciMap

Rasmussen

1997

Interacting systems
model for ergonomics
Software-hardwareenvironment-liveware
model
Human-systems
integration
Human factors
analysis and
classiﬁcation system
Functional resonance
analysis method

Wilson

2000

Rizzo et al.

2000

Originally developed to improve working
conditions for employees; subsequent
developments incorporated design of
information systems
To understand and resolve problems
relating to technology transfer of systems to
different environments
To analyse accident causes using the
system-based risk management approaches
To understand and model human factors
and ergonomics using systems thinking
To proactively analyse safety issues

Booher

2003

Wiegmann and
Shappell

2003

Hollnagel

2004/2012

Macro-ergonomics
approach
Ergonomic work
analysis (activityrelated ergonomics)
Model of work
system

Hendrick and Kleiner
Kleiner
Montmollin
Wisner
Daniellou
Smith and Sainfort
Carayon and Smith
Carayon
Dejours

2001
2008
1981/1988
1995
2004/2006
1989
2000
2009
1980/2009

Psychodynamics of
work
Systems theoretic
accident modelling
and processes

Table III.
Socio-technical
systems models

Leveson

2004
2012

To design and deploy complex systems
through user-centred approaches
To identify human causes of accidents and
incidents through a process tool for
investigation
To, prospectively or retrospectively,
analyse how work activities occur
(historically applied to accident analysis
activities and used as risk assessment tool)
To entrench macro-ergonomics techniques
to work design
To improve working conditions by using
employee activities as input, and to also
promote productivity, quality and health
To understand and model employee safety
and well-being by using systems thinking
To improve employee working conditions
to enhance the relationship between
employees and their work activities
To provide the basis for accident/incident
investigations, hazard analysis, accident
prevention, design for safety and safer
operations

Source: Trist and bamforth, 1951; Trist, 1981; Mumford, 2006; Davis et al., 2014; Carayon et al., 2015; Wu
et al., 2015




categorise data accordingly; and
compile ﬁnal report on “joint optimisation practices” as the main output/deliverable
of the process.

A better understanding of how the human, social and environmental factors affect the ways
in which work is performed and technical systems operated is dictated to by the outcome of
the appropriate application of the STS methods (Baxter and Sommerville, 2011).
In the next subsection, the execution of Steps 2 and 3 of the STS-CF development
methodology are discussed. In these steps, the joint optimisation process is applied to

inputs are

Organisational
practices

Capability Domains
Joint Optimisation
Process

Social dimension
Structure
Actors

Cybersecurity
framework

243

Technical dimension
Technology
Work activities

Environmental dimension

outputs are

Joint optimisation
practices

generate the socio-technical systems information and cybersecurity controls in an
organisation.
3.1.4 Joint optimisation security controls: application of joint optimisation process. To
accomplish the joint optimisation state of organisational systems security, a balanced set of
social and technical controls as inﬂuenced by the external environment are required. To
achieve this, the joint optimisation analysis process is used to analyse the selected
information and cybersecurity frameworks presented in Table IV.
In terms of the joint optimisation analysis process’ operational steps, the data gathered
refers to each security control of the selected information and cybersecurity framework.
Table V presents the analysis results of the frameworks. The individual security controls
are listed in Appendix A per framework. Each information and cybersecurity framework
control passes through the joint optimisation process as input. These inputs are then
analysed by the core function of the process. The analysis results are presented in Table V
as either having “Fulﬁlled”, “Not fulﬁlled” or “Partially fulﬁlled” a dimension of the joint
optimisation process. As stated previously, the joint optimisation analysis process’ outputs
are the actual security controls categorised into either the social, technical, or the
environmental dimension of a socio-technical system.
As shown in Table V, only seven out of ﬁfteen frameworks partially fulﬁl the security
user requirements of the social dimension of a socio-technical system. The analysis further
shows that all the frameworks in Table V completely fulﬁl the security user requirements of
the technical dimension of a socio-technical system. A conclusion is drawn from these
results that a socio-technical gap exists in all the analysed information and cybersecurity
frameworks. Figure 2 illustrated that a socio-technical gap exists where either one of the two
main STS dimensions is emphasised more than the other. This gap opens up an equal
vulnerability exposure through which cyber-attacks could succeed on both STS dimensions
but via the less emphasised one. This is apparent from the failures of some of the existing
technical “solutions” (Davis et al., 2014).
Together, the categorised output security controls are referred to as the socio-technical
systems’ information and cybersecurity controls (or simply joint optimisation security
controls) as shown in Table VI. These were synthesised and categorised from the seven

Figure 4.
Joint optimisation
analysis process,
derived from White
and Bruton (2011)

ICS
27,2

244

Table IV.
Information and
cybersecurity
frameworks

Information security
framework
Systems Security
Engineering Capability
Maturity Model (SSECMM)
Information Security
Management Systems
(ISO/IEC 27002)
Information Technology
Capability Maturity
Framework (IT-CMF)
Information Security
Maturity Model (ISM2)
Information Security
Management Maturity
Model (ISM3)
ISO/IEC 21827 (Improved
SSE-CMM)
Information Security
Framework (ISF)
Risk Management
Framework to Federal
Information Systems
(NIST-RMF)
Cybersecurity Emergency
Response Team Resilience
Management Model
(CERT-RMM)
The Open Group
Information Security
Management Maturity
Model (O-ISM3)
COBIT 5.0 for Information
Security
National Initiative for
Cybersecurity Education
Cybersecurity Workforce
Framework (NICE-CWF)
National Initiative for
Cybersecurity Education
Capability Maturity
Model (NICE-CMM)
Version 2.0
NIST Cybersecurity
Framework (NIST-CF)
Core or Original
Cybersecurity Capability
Maturity Model (C2M2)
Electricity Subsector Cybersecurity Capability

Author/publisher

Year

Purpose

United States
National Security
Agency

2001

Software and systems engineering security
evaluation

International
Organisation for
Standardisation
Intel Corporation

2005/2013

NIST

2007/2016

2006

Recommended code of practice for
information security control objectives
Assessment and understanding of the
organisation’s information technology
capability maturities
Reviews and measurements of an
information security posture
Resource optimisation for cyber-incidents
prevention

ISM3 Consortium

2007

International
Organisation for
Standardisation
IBM

2008
2009/2013

NIST

2010/2017

Carnegie Mellon
University

2010/2016

Provision of information security,
operational resilience and business
continuity practices

The Open Group

2011/2017

Alignment of organisations’ business
missions and security compliance
requirements

ISACA

2012

Assessment of software and systems
engineering security activities as an ISO
standard
Analysis of information security gaps
between technology and business
Improvement of United States federal
information systems platforms against
cyberattacks

Control objectives for information and
related technologies security model
Provides common lexicon to categorise and
describe cybersecurity tasks for a
workforce

NIST

2013/2014/
2017

United States
Department of
Homeland
Security

2012/2014

Provides blueprint to deﬁne cybersecurity
requirements into categories

NIST

2014/2017

United States federal critical infrastructure
cybersecurity framework
Evaluation of cybersecurity capabilities
using maturity model

United States
Department of
Energy
United States
Department of
Energy

2014
2014

Improvement of cybersecurity capabilities
of the electricity subsector
(continued)

Information security
framework
Maturity Model (ESC2M2)
Oil and Natural Gas
Subsector - Cybersecurity
Capability Maturity
Model (ONG- C2M2)
Capability Maturity
Model Integration for
Security Management
(CMMI-SM)
Information Technology
Capability Maturity
Framework (IT-CMF)

Cybersecurity
framework
Author/publisher

Year

Purpose

United States
Department of
Energy

2014

Improvement of cybersecurity capabilities
of the oil and natural gas subsector

CMMI Institute

2015

Guideline practices to address information
security concerns in organisations

Innovation Value
Institute

2016

Assessment of information technology and
security capability maturity

Sources: ISACA, 2012; Borrett et al., 2013; Dasso et al., 2016; Dorville, 2014; Miron and muita, 2014; US
department of energy, 2014; Penn et al., 2015; Carcary et al., 2016; Caralli et al., 2016; Le and hoang, 2016;
Curley et al., 2016; Curley et al., 2017; NIST, 2017b; Newhouse et al., 2017

Information
security framework
ISO/IEC 21827
(Improved SSE-CMM)
ISO/IEC 27002
IT-CMF
ISM2
ISM3
ISF
NIST-RMF
CERT-RMM
O-ISM3
COBIT 5.0 for Information Security
NICE-CWF
NICE-CMM
NIST-CF
C2M2
CMMI-SM

Social
dimension

Technical
dimension



































Notes: Table legend:  Fulﬁlled;  Partially fulﬁlled;  Not fulﬁlled

frameworks in Table V that partially fulﬁlled the social dimension of a socio-technical
system according to the joint optimisation analysis process.
In other words, the joint optimisation security controls are the security user requirements
that must be consistently met for an organisation to maintain its desired level of security
capability maturity. The controls have been grouped together into four socio-technical
capability domains. These capability domains were derived from the STS theory and

245

Table IV.

Table V.
Joint optimisation
analysis results

ICS
27,2

STS
dimension

Capability
domain

Social

Organisational structure Information and cybersecurity principles
Information and cybersecurity policy
Speciﬁc information and cybersecurity policies driven by the
security competency area
Speciﬁc information security policies driven by other competency
areas within the organisation
Organisational risk management committee
Organisational behaviours
Organisational leadership
Information and cybersecurity strategy
Information and cybersecurity operational plan
Organisational policies
Information and cybersecurity budget
Information and cybersecurity awareness
User access and access proﬁle aligning with business
requirements
Information and cybersecurity controls
Security roles, responsibilities and accountabilities
Information and cybersecurity communication and training
Security compliance
Personnel disciplinary process
Information systems and technology domain change control
Information and cybersecurity software development life cycle
control
Information and cybersecurity measures change control
Personnel security
Cybersecurity programme strategy
Actors
Information and cybersecurity steering committee
Chief information security ofﬁcer
Information and cybersecurity manager
Information custodians/business owners
Information and cybersecurity sponsor
Stakeholders (internal)
Personnel
2.1 Technology
Template for information and cybersecurity stakeholders
Secure development
Dashboard for information and cybersecurity
Architecture framework for security
Material for information and cybersecurity awareness
Reports for information and cybersecurity review
Reports for information and cybersecurity performance
Adequately conﬁgured and secured systems aligned with
information and cybersecurity requirements and security
architecture framework
Adequate protection strategy against malware, intrusion attempts
and external attacks
General information and cybersecurity tools and resources
Knowledge and information management for all disciplines
2.2 Work activities
Formulate information and cybersecurity strategy
Establish and maintain information and cybersecurity
architecture
(continued)

246

Technical

Table VI.
Joint optimisation
security controls

Capability-building factors (set of competency practices)

STS
dimension

Environment

Capability
domain

Cybersecurity
framework
Capability-building factors (set of competency practices)
Establish information and cybersecurity governance
Develop information and cybersecurity operational plan,
including risk activities
Execute information and cybersecurity operational plan,
including risk activities
Identify and classify information
Assess, test and ensure information compliance
Test security in general
Manage ﬁnancial resources
Manage human resources
Manage asset inventory
Manage asset conﬁguration
Manage asset changes
Ensure information and cybersecurity business continuity
Conduct personnel security checks prior, during and upon
employment termination/change
Share cybersecurity information
Physical premises
Environmental control
Security for original equipment manufacturers
Stakeholders (internal)
Security for other suppliers
Protect and manage physical environment
Manage supplier service level agreements
Ensure compliance with legal and contractual requirements
Security for physical infrastructure

captured in Table I already. It is worth emphasising that at this stage the security controls in
Table VI are not optimised. They are just categorised according to STS capability domains.
A few critical infrastructure owners have turned to maturity models to provide a framework
for evaluating their security maturity capabilities (Miron and Muita, 2014). Maturity models
can also be used to estimate capabilities of the perceived cyber-adversaries (Heckman et al.,
2015). Better decision-making by managers has also been attributed to the utilisation
maturity models in certain instances (Le and Hoang, 2016). Maturity models are closely
examined in the next subsection with the aim of determining how the maturity of the
derived joint optimisation security controls can be measured.
3.2 Security controls maturity indicator model
In this section, execution of step 4 in the STS-CF development methodology is discussed. In
this step, the appropriate capability model for the measurement of the maturity of joint
optimisation security controls is developed. In general, there are three types of maturity
indicator models (Le and Hoang, 2016):
(1) Progression: Deﬁnes maturity levels as stages of achievement, e.g. human
locomotion progression from crawling, walking, to running.
(2) Capability: Deﬁnes maturity levels as the degree to which organisational abilities
have been optimised, e.g. the maturity model in Figure 5.

247

Table VI.

ICS
27,2

248

Figure 5.
Five-stage process
maturity model,
derived from
Heckman et al. (2015)
and Le and Hoang
(2016)

(3)

Hybrid: The optimal grouping of both the capability and progression maturity
models in which maturity levels express both the degree of achievement and
capability.

This research was mainly concerned with measuring the degree to which an organisation can
optimise its socio-technical systems security capabilities. That is, accomplish security joint
optimisation capabilities. In this regard, the capability maturity model was found to be
appropriate for the study. The word capability is deﬁned by Williams (2008) as the quality of
possessing the required attributes, mental or physical, for accomplishment or successful
performance. Wendler (2012) views capability as the ability, whether intellectual or physical, to
successfully and consistently accomplish the intended goals and objectives. On the one hand,
the level of maturity of a capability indicates the degree to which practices are formalised and
optimised (Heckman et al., 2015). On the other hand, a model represents a simpliﬁed
representation of a system that attempts to give a detailed account of the workings of
phenomena (Le and Hoang, 2016). In this regard, a capability maturity model represents an
investigative tool to support the understanding and improvement of processes to, for example,
achieve the desired growth and performance objectives (Carroll and Helfert, 2015).
Originating in the software development industry, capability maturity models initially
represented organisational capability improvement paths for a software development
process maturity (Wendler, 2012). In particular, Watts Humphrey was the ﬁrst to
recommend, in 1989, the utilisation of a capability maturity model to evaluate the software
development process maturity (Le and Hoang, 2016). These are evaluated through different
levels as shown in Figure 5.
Carroll and Helfert (2015) also observed that the theoretical basis for a capability maturity
model is anchored around the desire to evaluate strategies for process improvement through a
number of deﬁned maturity levels which represent organisational growth. Indeed, the premise
upon which capability maturity models are created is that of improvement, achieved through
appraisal of internal and external organisational processes (Williams, 2008). However,
capability maturity models are not without criticism. According to Williams (2008), capability
maturity models are process and technology intensive, and progression from a lower to a
higher level does not necessarily reﬂect the change process of human involvement. Thus, it is
necessary to understand the structure and characteristics of a capability maturity model to
investigate its possible adaptation and suitability to the socio-technical systems information
and cybersecurity study. The conﬁguration of capability maturity models is such that they
comprise a structured set of elements (Wendler, 2012) that deliver a coherent blueprint to enable
organisations to determine and improve their security capabilities (Heckman et al., 2015).
Essentially, the main objective of a capability maturity model is to optimise processes and
practices to generate a greater return on investments (Carroll and Helfert, 2015). Table VII
shows maturity indicator models of the selected information and cybersecurity frameworks.
The main objective here is to use the data in Table VII to derive the appropriate and suitable
Level 5: Optimising

Organisation’s processes are continuously improved

Level 4: Managed

Processes are proactively defined and managed

Level 3: Defined

Processes are proactively defined

Level 2: Repeatable

Processes are reactive

Level 1: Initial

Processes are poorly defined

Capability maturity model

Number
of levels

SSE-CMM

5

IT-CMF

5

ISM3

5

ISF

3

NIST

5

O-ISM3

5

COBIT

6

NICE-CMM

3

C2M2

4

US Department of Energy

4

Level
description
Level 1: Base practices are performed informally
Level 2: Base practices are planned and tracked
Level 3: Base practices are well deﬁned
Level 4: Base practices are controlled
Level 5: Base practices are continuously improving
Level 1: Initial
Level 2: Basic
Level 3: Intermediate
Level 4: Advanced
Level 5: Optimising
Level 1: Undeﬁned
Level 2: Deﬁned
Level 3: Managed
Level 4: Controlled
Level 5: Optimised
Level 1: Basic
Level 2: Proﬁcient
Level 3: Optimised
Level 1: Policies
Level 2: Procedures
Level 3: Implementation
Level 4: Test
Level 5: Integration
Level 1: Initial
Level 2: Managed
Level 3: Deﬁned
Level 4: Controlled
Level 5: Optimised
Level 0: Non-existent
Level 1: Initial/ad hoc
Level 2: Repeatable but intuitive
Level 3: Deﬁned process
Level 4: Managed and measurable
Level 5: Optimised
Level 1: Limited
Level 2: Progressing
Level 3: Optimising
MIL 0: Practices are not performed
MIL 1: Initial practices exist but may be ad hoc
MIL 2: Practices are more complete than at MIL1
MIL 3: Practices are more complete than at MIL2
Level 0: Practices not performed
Level 1: Initial practices performed but ad hoc
Level 2: Initial institutionalisation of practices
Level 3: Institutionalised practices managed

capability maturity model to measure the degree to which the joint optimisation security
controls are formalised and optimised.
It has already been established that, through appraisals, the fundamental goal of a
capability maturity model is to optimise organisational processes and practices

Cybersecurity
framework

249

Table VII.
Information and
cybersecurity
capability maturity
models

ICS
27,2

250

(Williams, 2008; Carroll and Helfert, 2015). As shown in Table VII, the research evaluated
ten capability maturity models associated with the selected information and cybersecurity
frameworks. Based on the review and analysis of the ten maturity indicator models in Table
VII, a six-level capability maturity model to indicate the level of maturity for each joint
optimisation security control is proposed in Figure 6.
With reference to Figure 6, attaining higher maturity levels only serves as a guide to
effective work practices within organisations (Williams, 2008). By design, the maturity
indicator model in Figure 6 makes it highly unlikely, if not impossible, for an organisation to
attain a higher security capability level, say level 3, if the previous level has not been achieved.
Essentially, capability maturity evaluation models help guide organisations to assess
competency practices (Carroll and Helfert, 2015). For example, these models can help improve
the efﬁcacy and maturity of critical infrastructure security controls to perfect organisational
cybersecurity capabilities (Miron and Muita, 2014; Le and Hoang, 2016). In the next section, the
ﬁnal two steps of the STS-CF development methodology (Figure 1) are discussed. These are the
ﬁnal execution steps of the methodology to design, develop and validate the STS-CF.
4. Socio-technical systems cybersecurity framework
4.1 STS-CF development
Like NIST’s (2017b) cybersecurity framework for critical infrastructure (Cybersecurity
framework version 1.1), the STS-CF in Figure 7 was designed to complement, rather than
replace, the existing cybersecurity processes and business operations. The framework is,
especially, intended to provide an overarching blueprint for organisations to ensure that the
existing information and cybersecurity solutions do not leave any socio-technical gaps.
These gaps could be exploited by cyber-attackers with unpleasant consequences. The STSCF consists of three major building blocks: Joint optimisation process, joint optimisation
security controls and maturity indicator levels. The combined ultimate aim of the building
blocks are to drive high levels of information and cybersecurity capabilities within the
organisation.
4.1.1 Joint optimisation analysis process building block. This building block was
described in details in subsection 3.2.2. Essentially, the joint optimisation process
transforms input organisational practices, for example, security practices, into output sociotechnical practices inﬂuenced by the complex environment within which they are executed.
The building-block comprises of four capability domains forming the social, technical, and

Figure 6.
Joint optimisation
security controls’
maturity indicator
model

Level 5: Optimising

The socio-technical systems cybersecurity programme has been terminated and processes are
embedded within daily organisational practices. In addition, the socio-technical systems information
and cybersecurity practices have become fully automated and seamlessly integrated into the overall
security strategy of the organisation.

Level 4: Measurable outcomes

Proactive performance monitoring and evaluation of the socio-technical systems information and
cybersecurity practices by management. Where processes appear not to be effective, mitigating
actions are undertaken. Limited usage of automated tools is supplemented by continuous process
improvement.

Level 3: Formalised processes

There is a formal socio-technical systems cybersecurity framework programme in place. Processes
have been formally defined and documented. Policies, processes, and procedures have also been
communicated through awareness and training. The procedures themselves are not yet advanced but
are the mandated and formalised practices.

Level 2: Basic

Although no formal socio-technical systems cybersecurity framework processes exist. Some basic
processes are being followed. However, these are followed by different business units with no
standardised procedures and there is heavy reliance on the knowledge of individuals and terefore a
tendency to make mistakes.

Level 1: Haphazard

The organisation has realised the need to equally emphasise the social and technical dimensions of
information and cybersecurity. However, no standardised socio-technical systems cybersecurity
framework processes exist; instead, there are haphazard and disorganised approaches.

Level 0: Non-existent

There is no socio-technical systems cybersecurity framework programme in place.

environmental dimensions of an organisation. Conceptually, the social dimension comprises
of the organisational structure and actors, whereas the technical dimension consists of the
technology and work activities. The environmental dimension cuts across both the social
and technical dimensions. As developed and described mainly in Table I, the following
capability domains were derived mainly from Trist (1981), Mumford (2006), Davis et al.
(2014), Hester (2014), Wu et al. (2015) and Oosthuizen and Pretorius (2016):
Organisational structure. The purpose of the structure of the organisation is to emphasise
functions executed by particular process or competency areas towards attaining security.
The organisational structure components include roles and responsibilities, culture, values,
communication and reporting structures.
Actors. The purpose of the actors in the organisation is to emphasise the role played by
human beings towards attaining security. The actors include management and employees,
the board and other stakeholders (internal and external) who execute or inﬂuence the way
work organisational tasks are carried out.
Technology. The purpose of technology in the organisation is to emphasise the tools and
resources used by people in carrying out work activities (competency practices or capabilitybuilding factors) towards attaining security. The technology includes any useful technical
resources that can aid humans in performing their security duties, for example information,
equipment, frameworks and computers.
Work activities. The purpose of work activities in the organisation is to emphasise the
deﬁnition and execution of relevant tasks by people in different process and competency
areas, using tools and resources, towards security. The work activities refer to the actual
tasks and the manner in which they should be carried out.
Once the input organisational practices are fed into a transformational function that is
the joint optimisation process, socio-technical systems outputs are expected on the other
side. The next building-block of the STS-CF discusses how the conventional information
and cybersecurity practices have been transformed into socio-technical systems
cybersecurity practices.
4.1.2 Joint optimisation security controls building block. The purpose of this building
block as described in subsection 3.1.4 is not to prescribe the particular security controls to be
followed or as presented in Table VI.

Cybersecurity
framework

251

Joint Optimisation Analysis Process
STS-CF
Socio-technical Systems
Cybersecurity Framework

contains

Social dimension
Structure
Actors

Technical dimension
Technology
Work activities

Which drives

Information and Cybersecurity
Capability

Environmental Dimension

outputs are

Maturity
Indicator Model

evaluated by

Joint Optimisation
Security Controls

Which drive

improved by

Which helps determine

Continuous
Capability Improvement
Outcomes

Which drive

Figure 7.
Socio-technical
systems
cybersecurity
framework, derived
from United States
Department of
Energy (2014) and
Curley et al. (2016)

ICS
27,2

252

Rather, this building block merely represents the output of the security user
requirements exercise embarked upon in the joint optimisation process. That is, the
joint optimisation security controls will be unique for every organisation for their
environmental factors vary greatly. Hence, Table VI is just an example of what the joint
optimisation process outputs of an organisation could look like. Nothing more should
be read from Table VI.
4.1.3 Maturity indicator levels building block. The purpose of this building-block as
shown in Figure 7 and described in subsection 3.2. is to determine the level of maturity for
each joint optimisation security control. It is through the continuous monitoring and
improvement of the joint optimisation security practices that an organisation can
accomplish their desired levels of information and cybersecurity capabilities.
4.1.4 Continuous capability improvement outcomes building block. The purpose of this
building block is to continuously monitor and improve the joint optimisation state of the
information and cybersecurity controls. To be able to monitor this so that an organisation
can determine where appropriate interventions are required, a parameter must be measured.
The procedure to compute and measure such a parameter is derived from Sabiers (1998) and
Washington and Hacker (2000) as follows:
Facilitate the ranking of each “joint optimisation process” output based on the perceived
value of the security controls in the organisation using a Likert-type scale.
In a tabular format, aggregate the scores per STS dimension (technical, social, and
environmental) using the “system equivalence” formula below:
System equivalence ¼

½Max:system score ðsocial; technical; environmentÞ 6¼ Min system score ðsocial; technical; environmentÞ
Average score ðsocial; technical; environmentÞ

Washington and Hacker (2000) deﬁne system equivalence as the state at which all three STS
dimensions are mutually equivalent in value. In other words, the system equivalence is the
parameter to measure to continuously monitor and improve the joint optimisation state of
the information and cybersecurity controls. The ﬁrst measurement of the parameter will
form the baseline measurement. A decrease of the parameter from the baseline represents an
STS cybersecurity performance improvement. Similarly, an increase in the parameter in
relation to the baseline represents deterioration in cybersecurity performance and an
intervention is needed urgently. Thus, an organisation improves its cybersecurity joint
optimisation only when the gap between its more emphasised (best performing) and less
emphasised (less performing) STS dimension is reduced (Washington and Hacker, 2000).
When this is achieved, the overall performance of the STS system is improved. Furthermore,
close scrutiny of the STS dimensions’ individual and aggregated scores should reveal where
the increase/decrease of the system equivalence parameter emanated from. This makes it
relatively easy for organisations to implement appropriate interventions thereby validating
the STS-CF.
4.2 STS-CF validation
The task undertaken to evaluate the maturity of a technology is called technology maturity
assessment, a term used by US’ national aeronautics and space administration.
The US’ Department of Defense describes the same task as technology readiness
assessment (Salim et al., 2016). According to Salim et al. (2016), the term “technology
maturity” can be used interchangeably with “technology readiness”. However, Tetlay and
John (2009) disagree. These researchers hold a contrary view that it is both necessary and
useful to consider maturity as distinct from readiness. Maturity relates to the veriﬁcation of

a process, system, technology, or capability against user requirements, whereas readiness
has to do with the validation against user requirements within speciﬁed operating
conditions (Tetlay and John, 2009). In this research, the notion that maturity (user
requirements are met) and readiness (system operates according to user requirements under
speciﬁed conditions) are two distinct concepts is adopted. In other words, the capability
maturity model in Figure 7 is used only to verify the maturity of the implemented joint
optimisation security controls.
However, the overall results of the continuous monitoring of the implemented joint
optimisation security controls under speciﬁed operating conditions are intended to validate
the STS-CF; that is, validate the readiness of the STS-CF. As future work, the researchers
plan to validate the STS-CF through interviews with security experts in both the
governmental and private sectors. Access request to conduct focus group interviews with
security experts in the governmental sector has already been initiated. The researchers plan
to supplement this by further interviewing security experts in the private sector. The private
sector experts have also been identiﬁed through the 2017 and 2018 security summits, an
annual cybersecurity event by industry in South Africa.
5. Discussions, recommendations and future research
5.1 Discussions
Discussions in this paper are centred on three sub-objectives of the main research objective
described in the introduction section. The ﬁrst sub-objective was focused on the
development of a socio-technical systems analysis process model to identify socio-technical
gaps within any system. The analysis process model is called the joint optimisation process
and was developed from the socio-technical systems theory. In particular, Table I was
derived from the STS theory and it was out of Table I that the joint optimisation process
was synthesised. To apply the joint optimisation process model for identiﬁcation of sociotechnical gaps in any organisational practices, data (social, technical, and environmental)
should ﬁrst be gathered usually in the form of a survey within the organisation. Once the
data is gathered, an objective facilitator must conduct workshops to help participants
classify and categorise the data into either the social, technical, or environmental dimension.
The ﬁnal output of this whole exercise is the joint optimisation practices in the organisation.
The main advantage of this approach is that various stakeholders in the organisation would
be involved. Anything that would have fallen through the cracks had the process been
performed by the information technology (IT) business unit only would be picked-up. The
main disadvantage of the process, however, is potential for both technical and cognitive bias
from the participants. For example, participants from the non-technical business units such
as human resources, marketing and ﬁnance, would lean towards practices that are less
technical and similarly participants from the more technical business units such as IT,
engineering and manufacturing, would be biased towards practices that are more technical.
A very strong and impartial facilitator is therefore required for this exercise. For the
purposes of the study, security practices from the selected frameworks on information and
cybersecurity served as the data.
The second research sub-objective was to apply the joint optimisation process to identify
any socio-technical gaps to the selected information and cybersecurity framework practices.
This process model can also be used to analyse other organisational practices besides
information and cybersecurity practices. The results presented in Table VI are only indicative
of the expected output of the application of the joint optimisation process to the information and
cybersecurity framework practices. They are by no means to be interpreted as the prescribed
joint optimisation security controls. Moreover, the results of such an exercise are intended to

Cybersecurity
framework

253

ICS
27,2

254

expose any existing socio-technical gaps in an organisation’s current information and
cybersecurity solution. The same multi-stakeholder advantages and bias disadvantages
described above apply here since the process execution is the same. The third and ﬁnal
research sub-objective focused on the ultimate research goal of developing a socio-technical
systems cybersecurity framework to assist organisations in closing any socio-technical gaps to
their existing information and cybersecurity solutions. Together with two additional building
blocks, the application of the joint optimisation process to the information and cybersecurity
domain and its output culminates into the STS-CF. The two additional processes are the
capability maturity indicator model as well as the continuous capability improvement
outcomes. On the one hand, the capability maturity indicator reﬂects the degree to which
organisational information and cybersecurity capabilities have been optimised on a scale from
level 0 (non-existent) to level 5 (optimising). On the other hand, the continuous capability
improvement outcomes measure and track a parameter called the system equivalence. The
parameter is aggregated for all three STS dimensions.
5.2 Recommendations
As stated previously, the STS-CF was designed to complement, rather than replace, existing
cybersecurity processes and business operations within organisations (NIST, 2017b). The
framework should help organisations identify any cybersecurity vulnerability gaps resulting
from the misalignment of the social and technical security dimensions in a complex
environment. Essentially, the STS-CF is meant to serve as a complementary security model to
help organisations accomplish their joint optimisation state. A perfect alignment of the four
STS capability domains (structure, actors, technology, and work activities) is therefore a
prerequisite for an ideal information and cybersecurity solution. Implementing such a
framework will also prove to be a great challenge. The fundamental driver for the
implementation of the STS-CF is an organisation’s information and cybersecurity/risk
management strategy. As can be seen in Figure 8, the researchers recommend how and where
the STS-CF ﬁts into the overall security programme of an organisation. According to Jairak and
Praneetpolgrang (2013), the IT governance principles include information security, risk
management, IT resources management, service quality, and business/IT alignment. Having
developed the framework on the governance and management of enterprise IT, ISACA is also
the parent company of the IT Governance Institute. In this regard, the researchers saw it ﬁt to
derive an STS-CF governance framework based on the IT Governance Institute’s (2006)
governance model. It is clear from Figure 8 that the STS-CF programme should not be
implemented in isolation. Further, the implementation workshops begin with socio-technical
user requirements exercise that generates outcomes to form the baseline cybersecurity controls.
The continuous monitoring of the level of maturity for each baseline control must deliberately
be pursued by management for process improvement. This should lead to security process
optimisation. Where security competency practices appear not to be effective, management
should further implement mitigating actions.
Accordingly, the researchers recommend steps 1 through 4 below only as a guideline for
implementing the STS-CF. The steps were derived from the USA Department of Energy
(2014) and NIST (2017b). They illustrate how an organisation can go about implementing
the STS-CF to identify and close socio-technical gaps in the existing information and
cybersecurity solutions. The assumption here is that an organisation already has an
enterprise-wide cybersecurity/risk management strategy.
Step 1: Requirements analysis. The chief security ofﬁcer, together with a steering
committee, develop the overall cybersecurity/risk management strategy and aligns the
desired socio-technical systems cybersecurity outcomes with it. This ensures that the

Business Strategy

Cybersecurity
framework

Strategic Objectives

Information and Cybersecurity
Strategy

STS-CF Requirements

STS-CF Policy, Standards,
Processes, Procedures

STS-CF Programme

255

STS-CF
Definition

STS-CF Implementation

Framework
Verification

STS-CF Outcomes

Framework
Validation

Continuous
Capability Improvement
Outcomes

Maturity Indicator Model

System Equivalence Parameter

implementation of the STS-CF does not go off on a tangent but addresses speciﬁc security
requirements and strategic objective(s). At this stage, workshops are also held in the
organisation to gather, identify and classify information and cybersecurity data according
to the social, technical and environmental dimensions. All other relevant stakeholders are
also identiﬁed at this stage.
Deliverable: Preliminary joint optimisation security controls report.
Step 2: Gap analysis. The gathered existing/new information and cybersecurity practices
are analysed further. The socio-technical gaps are identiﬁed throughout the organisation.
The joint optimisation security controls report is now ﬁnalised. The baseline service
equivalence parameter is also computed at this stage. Intervention areas for optimisation are
identiﬁed and resources pulled together. This culminates into an operational plan.
Deliverable: Final joint optimisation security controls report; Operational plan.
Step 3: Prioritise and plan. Identify initiatives/projects required to roll out the joint
optimisation security operational plan. List the initiatives according to priority of execution
(depending on the available budget, timeline, skilled personnel and urgency of strategic
objectives). This will also inform the CSO if there is internal capacity to implement the STS-

Figure 8.
STS-CF governance
framework, derived
from the IT
Governance Institute
(2006)

ICS
27,2

256

CF or if an external service provider is required. Based on the operational plan, develop the
joint optimisation security action plan (s). Ensure that the action plan (s) is/are aligned with
both the enterprise security and business strategies.
Deliverable: Joint optimisation security programme action plan (s).
Step 4: Implement and monitor. Execute the joint optimisation security programme
action plan (s) to achieve strategic objective(s). In other words, implement the STS-CF and
continuously monitor the outcomes for improvement.
Deliverable: STS-CF outcomes and monitoring for continuous process improvement.
Through the continuous measurement and monitoring of the STS-CF outcomes, the
opportunity arises to both validate the framework and improve on its effectiveness. The
results of monitoring can also assist researchers in identifying areas for future research.
5.3 Future research
As the engine of the STS-CF, the joint optimisation analysis process can be applied to other
domains for further security research:
 blockchain security;
 cloud computing security;
 edge computing security;
 Internet of Things security; and
 artiﬁcial intelligence security.
Furthermore, the application of linear programming to solve the joint optimisation problem
as deﬁned in this research more accurately than is currently proposed is also an opportunity
for future research. Linear programming is a mathematical approach to determining a
means to achieve the best possible outcome in a given situation where there are three sets of
basic variables: decision variables, result variables and uncontrollable variables (Zhang
et al., 2015). This approach could give rise to software that could be used for more accurate
and unbiased results.
6. Conclusion
The literature has shown that people-centred approaches have the unique inﬂuence to
inform better and holistic systems security solutions. One of the observed common themes
between several security threats and vulnerabilities is that security is often treated in a
piecemeal approach by different security professionals and at different times, probably
using different methods dedicated at one system layer at once. The literature has shown that
this opens up vulnerabilities that an attacker can exploit. The socio-technical systems
security approach, which is about holistically understanding and formalising the
interactions between people and systems without emphasising one aspect more than the
other, was adopted by the research for a different security perspective. This perspective is
called joint optimisation – an STS approach that places equal emphasis on both the social,
technical, and environmental dimensions of organisational work practices. Subsequently, a
socio-technical systems cybersecurity framework which consists of four major components
(joint optimisation process, joint optimisation security controls, maturity indicator model,
and continuous capability improvement outcomes) was developed. Finally, the steps to
implement the STS-CF programme were recommended. The recommendations show how an
organisation can implement the STS-CF to socio-technically optimise an existing
technocentric security programme. Moreover, a governance framework on how and where

the STS-CF programme ﬁts into the overall enterprise risk and security management
architecture was recommended.
References
Al-Daraiseh, A.A., Al-Joudi, A.S., Al-Gahtani, H.B. and Al-Qahtani, M.S. (2014), “Social networks’
beneﬁts, privacy, and identity theft: KSA case study”, International Journal of Advanced
Computer Science and Applications, Vol. 5 No. 12, pp. 129-143.
Appelbaum, S.H. (1997), “Socio-technical systems theory: an intervention strategy for organisational
development”, Management Decision, Vol. 35 No. 6, pp. 452-463.
Baxter, G. and Sommerville, I. (2011), “Socio-technical systems: from design methods to systems
engineering”, Interacting with Computers, Vol. 23 No. 1, pp. 4-17.
Beekun, R. (1989), “Assessing the effectiveness of sociotechnical interventions: antidote or fad?’”,
Human Relations, Vol. 42 No. 10, pp. 877-897.
Bella, G., Curzon, P. and Lenzini, G. (2015), “Service security and privacy as a socio-technical problem”,
Journal of Computer Security, Vol. 23 No. 5, pp. 563-585. No
Borrett, M., Buecker, A., Arunkumar, S., Blackshaw, B., Brittenham, P., J. Jacobs, J, F., Jeremic, V.,
Johnston, M., Mark, C., Marx, G., Van Daele, S. and Vereecke, S. (2013), Using the IBM Security
Framework and IBM Security Blueprint to Realize Business-driven Security, 3rd edition,
Redbooks, IBM Corporation, Armonk, New York, NY.
Bostrom, R.P. and Heinen, J.S. (1977), “MIS problems and failures: a socio-technical perspective; part I:
the causes”, MIS Quarterly, Vol. 1 No. 3, pp. 17-32.
Budzak, D. (2016), “Information security – the people issue”, Business Information Review, Vol. 33 No. 2,
pp. 85-89.
Caralli, R.A., Allen, J.H., Curtis, D.P., White, D.W., Young, L.R. and Mehravari, N. (2016), “CERT®
resilience management model, version 1.2”, available at: www.cert.org/downloads/resilience/
assets/cert-rmm-v1-2.pdf (accessed 5 January 2018).
Carayon, P., Hancock, P., Leveson, N., Noy, I., Sznelwa, L. and Van Hootegem, G. (2015), “Advancing a
sociotechnical systems approach to workplace safety – developing the conceptual framework”,
Ergonomics, Vol. 58 No. 4, pp. 548-564.
Carcary, M., Renaud, K., McLaughlin, S. and O’Brien, C. (2016), “A framework for information security
governance and management”, IT Professional, Vol. 18 No. 2, pp. 22-30.
Carroll, N. and Helfert, M. (2015), “Service capabilities within open innovation: revisiting the
applicability”, Journal of Enterprise Information Management, Vol. 28 No. 2, pp. 275-303.
Chen, S.P. and Redar, J.M. (2014), “Ageing workforce knowledge management and transactional and
transformational leadership: a socio-technical systems framework and a norwegian case study”,
International Journal of Business and Social Science, Vol. 5 No. 5, pp. 11-21.
Craigen, D., Diakun-Thibault, N. and Purse, R. (2014), “Deﬁning cybersecurity”, Technology Innovation
Management Review, Vol. 4 No. 10, pp. 13-21.
Curley, M., Kenneally, J. and Carcary, M. (2016), IT Capability Maturity FrameworkTM (IT-CMFTM): the
Body of Knowledge Guide, 2nd edition, Van Haren, Zaltbommel, Netherlands.
Curley, M., Kenneally, J., Carcary, M. and Kavanagh, D. (2017), “IT-CMF – A management guide: based
on the IT capability maturity frameworkTM (IT-CMFTM)”, 2nd edition, Van Haren, Zaltbommel,
Netherlands.
Dasso, A., Funes, A., Montejano, G., Riesco, D., Uzal, R. and Debnath, N. (2016), “Model based evaluation of
cybersecurity implementations in information technology: new generations”, in Proceedings of the
13th international conference on information technology, Springer Verlag, pp. 303-313.
Davis, M.C., Challenger, R., Jayewardene, D.N.W. and Clegg, C.W. (2014), “Advancing socio-technical
systems thinking: a call for bravery”, Applied Ergonomics, Vol. 45 No. 2, pp. 171-180.

Cybersecurity
framework

257

ICS
27,2

258

Dellios, K., Papanikas, D. and Polemi, D. (2015), “Information security compliance over intelligent
transport systems: is IT possible?”, IEEE Security and Privacy, Vol. 13 No. 3, pp. 9-15.
Dorville, K. (2014), “Department of homeland security: cybersecurity capability maturity model, version
1.0”, available at: https://niccs.us-cert.gov/sites/default/ﬁles/Capability%20Maturity%20Model
%20White%20Paper.pdf?trackDocs= Capability%20Maturity%20Model%20White%20Paper.
pdf (accessed 6 January 2018).
Egan, T.M., Yang, B. and Barlett, R.B. (2004), “The effects of organisational learning culture and job
satisfaction on motivation to transfer learning and turnover intention”, Human Resource
Development Quarterly, Vol. 15 No. 3, pp. 279-301.
Emery, F.E. (1982), “Sociotechnical foundations for a new social order?”, Human Relations, Vol. 35
No. 12, pp. 1095-1123. No
Friedberg, I., McLaughlin, K., Smith, P., Laverty, D. and Sezer, S. (2017), “SafeSec: safety and security
analysis for cyber-physical systems”, Journal of Information Security and Applications, Vol. 34,
pp. 183-196.
Furnell, S. and Emm, D. (2017), “The ABC of ransomware protection”, Computer Fraud and Security,
Vol. 2017 No. 10, pp. 5-11.
Guitton, C. (2013), “Cyber insecurity as a national threat: Overreaction from Germany, France and the
UK?”, European Security, Vol. 22 No. 1, pp. 21-35.
Hadid, W., Mansouri, S.A. and Gallear, D. (2016), “Is lean service promising? A socio-technical perspective”,
International Journal of Operations and Production Management, Vol. 36 No. 6, pp. 618-642.
Heckman, K.E., Stech, F.J., Thomas, R.K., Schmoker, B. and Tsow, A.W. (2015), Cyber Denial, Deception
and Counter Deception: A Framework for Supporting Active Cyber Defense, Springer
International, Cham.
Hester, A.J. (2014), “Socio-technical systems theory as a diagnostic tool for examining underutilization
of wiki technology”, The Learning Organization, Vol. 21 No. 1, pp. 48-68.
Hollnagel (2017), “The functional resonance analysis”, available at: http://functionalresonance.com/
index.html (accessed 4 February 2018).
Hu, F., Lu, Y., Vasilakos, A.V., Hao, Q., Ma, R., Patil, Y., Zhang, T., Lu, J., Li, X. and Xiong, N.N. (2016),
“Robust cyber–physical systems: Concept, models, and implementation”, Future Generation
Computer Systems, Vol. 56, pp. 449-475.
ISACA (2012), COBIT 5® for Information Security, ISACA, Rolling Meadows, IL.
IT Governance Institute (2006), Information Security Governance: Guidance for Boards of Directors and
Executive Management, 2nd edition, Isaca, Rolling Meadows, IL.
Jairak, K. and Praneetpolgrang, P. (2013), “Applying IT governance balanced scorecard and
importance-performance analysis for providing IT governance strategy in university”,
Information Management and Computer Security, Vol. 21 No. 4, pp. 228-249.
Jing, Q., Vasilakos, A., Wan, J., Lu, J. and Qiu, D. (2014), “Security of the internet of things: perspectives
and challenges”, Wireless Networks, Vol. 20 No. 8, pp. 2481-2501.
Kenney, M. (2015), “Cyber-terrorism in a post-stuxnet world”, Orbis, Vol. 59 No. 1, pp. 111-128.
Laybats, C. and Tredinnick, L. (2016), “Information security”, Business Information Review, Vol. 33
No. 2, pp. 76-80.
Le, N.T. and Hoang, D.B. (2016), ““Can maturity models support cyber security?”, in Proceedings of the
35th IEEE international performance computing and communications conference, Las Vegas.
Leveson, N.G. (2004), “A new accident model for engineering safer systems”, Safety Science, Vol. 42
No. 4, pp. 237-270.
Miron, W. and Muita, K. (2014), “Cybersecurity capability maturity models for providers of critical
infrastructure”, available at: https://timreview.ca/sites/default/ﬁles/article_PDF/MironMuita_
TIMReview_October2014.pdf (accessed 1 September 2017).

Mumford, E. (2006), “The story of socio-technical design: reﬂections on its successes, failures and
potential”, Information Systems Journal, Vol. 16 No. 4, pp. 317-342.
Newhouse, W. Keith, S. Scribner, B. and Witte, G. (2017), “National institute of standards and
technology special publication 800-181: National initiative for cybersecurity education (NICE)
cybersecurity workforce framework”, available at: http://nvlpubs.nist.gov/nistpubs/
SpecialPublications/NIST.SP.800-181.pdf (accessed 28 December 2017).
NIST (2017a), “National institute of standards and technology special publication 800-53 revision 5:
Security and privacy controls for information systems and organizations, initial public draft”,
available at: https://csrc.nist.gov/csrc/media/publications/sp/800-53/rev-5/draft/documents/sp8
00-53r5-draft.pdf (accessed 31 December 2017).
NIST (2017b), “Framework for improving critical infrastructure cybersecurity, draft version 1.1”,
available at: https://www.nist.gov/sites/default/ﬁles/documents////draft-cybersecurity-framewo
rk-v1.11.pdf (accessed 1 September 2017).
Oosthuizen, R. and Pretorius, L. (2016), “Assessing the impact of new technology on complex sociotechnical systems”, South African Journal of Industrial Engineering, Vol. 27 No. 2, pp. 15-29.
Penn, M.L. Barletto, P.F. and Segnit, M. (2015), “Security management guide for CMMI v 1.3”, available
http://cmmiinstitute.com/sites/default/ﬁles/resource_asset/CMMI_Security_Management_
at:
Application_Guide_V4%200.pdf (accessed 1 September 2017).
Puthal, D., Nepal, S., Ranjan, R. and Chen, J. (2016), “Threats to networking cloud and edge datacenters
in the internet of things”, IEEE Cloud Computing, Vol. 3 No. 3, pp. 64-71.
Ray, S., Jin, Y. and Raychowdhury, A. (2016), “The changing computing paradigm with internet of
things: A tutorial introduction”, IEEE Design and Test, Vol. 33 No. 2, pp. 76-96.
Ross, R.S. McEvilley, M. and Oren, J. (2016), “National institute of standards and technology special
publication 800-160, systems security engineering – considerations for a multidisciplinary
approach in the engineering of trustworthy secure systems”, available at: http://nvlpubs.nist.
gov/nistpubs/SpecialPublications/NIST.SP.800-160.pdf (accessed 4 January 2018).
Russel, G. (2017), “Resisting the persistent threats of cyber-attacks”, Computer Fraud and Security,
Vol. 2017 No. 12, pp. 7-11.
Sabbagh, B.A. and Kowalski, S. (2012), ““ST(CS)2 - Featuring socio-technical cyber security warning
systems”, in Proceedings of the international conference on cyber security, cyber warfare and
digital forensic (CyberSec), Kuala Lumpur, Malaysia, pp. 312-316.
Sabiers, M. (1998), “The sociotechnical systems organization design assessment survey”, 3rd ed.,
SocioTech Solutions, Pound Ridge, New York, NY.
Salim, S., Lee, T. and Lee, J. (2016), “Technology readiness level as an exit criteria of early life cycle
phases for steel-making a plant”, in Proceedings of the 26th annual INCOSE international
symposium conference, Edinburgh, Scotland, UK.
Schuetz, C.G. and Schreﬂ, M. (2017), “Towards formal strategy analysis with goal models and semantic
web technologies. In: de cesare, S., frank, U. (Eds.). advances in conceptual modelling”, Lecture
Notes in Computer Science, Springer, Cham, Vol. 10651, pp. 144-153.
Soomro, Z.A., Shah, M.H. and Ahmed, J. (2016), “Information security management needs more holistic
approach: a literature review”, International Journal of Information Management, Vol. 36 No. 2,
pp. 215-225.
Tetlay, A. and John, P. (2009), ““Determining the lines of system maturity, system readiness and
capability readiness in the system development lifecycle”, in Proceedings of the 7th annual
conference on systems engineering research, Loughborough, United Kingdom.
The Open Group (2017), “Open information security management maturity model (O-ISM3), version
2.0”, available at: https://publications.opengroup.org/c17b (accessed 05 January 2018).
Trist, E. (1981), The Evolution of Socio-technical Systems, Quality of Working Life Center, Toronto.

Cybersecurity
framework

259

ICS
27,2

260

Trist, E.L. and Bamforth, K.W. (1951), “Some social and psychological consequences of the longwall
method of coal-getting: an examination of the psychological situation and defenses of a work
group in relation to the social structure and technological content of the work system”, Human
Relations, Vol. 4 No. 1, pp. 3-38.
Troyer, L. (2017), “Expanding sociotechnical systems theory through the trans-disciplinary lens of
complexity theory”, in Kahlen, J., Flumerfelt, S. and Alves, A. (Eds.), Transdisciplinary
Perspectives on Complex Systems, Springer, Cham.
Underwood, P. and Waterson, P. (2012), “A critical review of the STAMP, FRAM and accimap systemic
accident analysis models”, in Stanton, N. (Ed.), Advances in Human Aspects of Road and Rail
Transportation, CRC Press, Boca Raton, FL, United States, pp. 385 - 394.
US Department of Energy (2014), “Oil and natural gas subsector: Cybersecurity capability maturity
model version 1.1”, available at: https://energy.gov/sites/prod/ﬁles/2014/03/f13/ONG-C2M2-v11_cor.pdf (accessed 27 November 2017).
Van Heerden, R., Von Soms, S. and Mooi, R. (2016), ““Classiﬁcation of cyber attacks in South Africa”, in
Proceedings of the 11th IST-Africa week conference, Durban, South Africa.
Vuorinen, J. and Tetri, P. (2016), “Paradoxes in information security”, IEEE Potentials, Vol. 35 No. 5,
pp. 36-39.
Walker, G.H., Stanton, N.A., Jenkins, D., Salmon, P., Young, M. and Aujla, A. (2007), “Sociotechnical
theory and NEC system design”, in Harris, D. (Ed.), Engineering Psychology and Cognitive
Ergonomics, Springer-Verlag, Berlin.
Washington, M. and Hacker, M. (2000), “System equivalence: the application of joint optimization”,
Measuring Business Excellence, Vol. 4 No. 4, pp. 18-24.
Wendler, R. (2012), “The maturity of maturity model research: a systematic mapping study”,
Information and Software Technology, Vol. 54 No. 12, pp. 1317-1339.
White, M.A. and Bruton, G.D. (2011), The Management of Technology and Innovation: A Strategic
Approach, South-Western Cengage Learning, Mason, OH.
Whitworth, B. (2009), “A brief introduction to sociotechnical systems”, in Khosrow-Pour, M. (Ed.),
Encyclopedia of Information Science and Technology, 2nd edition, IGI Global, Hershey,
pp. 394-400.
Wiegmann, D.A. and Shappell, S.A. (2003), A Human Error Approach to Aviation Accident Analysis:
The Human Factors Analysis and Classiﬁcation System, Ashgate Publishing, Burlington, VT,
United States.
Williams, P. (2008), “A practical application of CMM to medical security capability”, Information
Management and Computer Security, Vol. 16 No. 1, pp. 58-73.
Wu, P.P., Fookes, C., Pitchforth, J. and Mengersen, K. (2015), “A framework for model integration and
holistic modelling of socio-technical systems”, Decision Support Systems, Vol. 71, pp. 14-27.
Wurm, J., Jin, Y., Liu, Y., Hu, S., Heffner, K., Rahman, F. and Tehranipoor, M. (2017), “Introduction to
cyber-physical system security: a cross-layer perspective”, IEEE Transactions on Multi-Scale
Computing Systems, Vol. 3 No. 3, pp. 215-227.
Zhang, G., Lu, J. and Gao, Y. (2015), “Multi-level decision making: models, methods and applications”,
Springer-Verlag, Berlin.
Further reading
Rigon, E.A. and Westphall, C.M. “Dos santos, D.R. and westphall, C.B. (2014), “A cyclical evaluation
model of information security maturity”, Information Management and Computer Security,
Vol. 22 No. 3, pp. 265-278.

Appendix. Competency practices of the information and cybersecurity frameworks

Capability
domain

Domain
practices

Practice
code

Risk
process

Assess threat
Assess vulnerability
Assess impact
Assess security risk
Verify and validate security
Build assurance argument
Specify security requirements
Provide security input
Coordinate security
Administer security controls
Monitor security posture

PA04
PA05
PA02
PA03
PA11
PA06
PA10
PA09
PA07
PA01
PA08

Assurance
process
Engineering
process

Domain
code

Capability
domain

Category A Governance

Category B
Category C

Category D
Category E
Category F

Domain
practices

Information security strategy
Security
policies and controls
Security roles, responsibilities and accountabilities
Communication
and training
Security performance reporting
Supplier security
Technical security
Security architecture
IT component security
Physical infrastructure security
Security risk control
Security threat proﬁling
Security risk assessment
Security risk prioritisation
Security risk handling
Security risk monitoring
Security data administration
Data identiﬁcation and classiﬁcations
Access rights management
Data life cycle management
Business continuity management Business continuity planning
Incident management
Security resource management
Budget for security
Tools and resources
Resource effectiveness

Cybersecurity
framework

261

Table AI.
ISO/IEC 21827 (ISO/
IEC 21827, 2008) and
SSE-CMM (Ross
et al., 2016)

Practice
code
CBB A1
CBB A2
CBB A3
CBB A4
CBB A5
CBB A6
CBB B1
CBB B2
CBB B3
CBB C1
CBB C2
CBB C3
CBB C4
CBB C5
CBB D1
CBB D2
CBB D3
CBB E1
CBB E2
CBB C1
CBB C2
CBB C3

Table AII.
IT-CMF (Carcary
et al., 2016; Curley
et al., 2017)

ICS
27,2

262

Table AIII.
ISO/IEC 27002 (ISO/
IEC 27002, 2013)

Domain Capability
code
domain

Domain
practices

A.5
A.6

Information security policies
Internal organisation
Mobile devices and teleworking
Prior to employment
During employment
Termination and change of employment
Responsibility for assets
Information classiﬁcation
Media handling
Business requirements of access control
User access management
User responsibilities
System and application access control
Cryptographic controls
Secure areas
Equipment
Operational procedures and responsibilities
Protection from malware
Backup
Logging and monitoring
Control of operational software
Technical vulnerability management
Information systems audit considerations
Network security management
Information transfer
Security requirements of information systems
Security in development and support processes
Test data
Information security in supplier relationships
Supplier service delivery management
Management of information security incidents and
improvements
Business continuity
Redundancies
Compliance with legal and contractual requirements
Information security reviews

A.7

Information security policies
Organisation of information
security
Human resources security

A.8

Asset management

A.9

Access
control

A.10
A.11
A.12

Cryptography
Physical and environmental
security
Operations security

A.13

Communications security

A.14

System acquisition,
development and maintenance

A.15

Supplier relationships

A.16

Information security incident
management
Business continuity
management
Compliance

A.17
A.18

Practice
code
A.6.1
A.6.2
A.7.1
A.7.2
A.7.3
A.8.1
A.8.2
A.8.3
A.9.1
A.9.2
A.9.3
A.9.4
A10.1
A.11.1
A.11.2
A.12.1
A.12.2
A.12.3
A.12.4
A.12.5
A.12.6
A.12.7
A.13.1
A.13.2
A.14.1
A.14.2
A14.3
A.15.1
A.15.2
A16.1
A.17.1
A.17.2
A.18.1
A.18.2

Domain
code

Capability
domain

Domain
practices

TA1

Information security management and
culture

TA2
TA3

Information security planning
Security awareness, training and
education

TA4

Budget
and resources

TA5

Life cycle
management

TA6
TA7
TA8

Certiﬁcation and accreditation
Critical infrastructure protection
Incident
response
Security
controls

IT roles and responsibilities
Security control review
Rules of behaviour and documentation
Personnel security
Risk management
System security plans
End-users’ security awareness and training
IT and security professionals’ awareness and
training
Management’s security awareness and training
Proper infrastructure for security awareness and
training
Capital planning that caters for IT security
Adequate resources applied to IT security
IT security funding allocated through a risk model
Cost-effective IT security solutions
Procurement controls
Governance process
Systems and projects inventory
System development life cycle methodology
Changes controlled and tested through the system
development life cycle methodology
Clearly deﬁned security requirements
Security accreditation and certiﬁcation
Protection of critical infrastructure
Disaster recovery and business continuity
Incident identiﬁcation, reporting and response
Environmental and physical security programme
Software and hardware security maintenance
System and information integrity
Protection of security media
User identiﬁcation and authentication
Logical access control
Audit trails
Protection of systems and communications channels

TA9

Cybersecurity
framework

263

Table AIV.
ISM2 PRISMA
(CSRC, 2017b)

ICS
27,2

264

Domain
code

Capability
domain

Domain
practices

Practice
code

GP

General

SSP
TSP

Strategic management
Tactical management

OSP

Operational management

Document management
ISM system and business audit
ISM design and evolution
Allocate resources for information security
Manage allocated resources
Deﬁne security targets
Security personnel selection
Security personnel training
Disciplinary process
Security awareness
Select tools for implementing security measures
Security measures change control
Malware protection management
Access control
User registration
Physical environment protection management
Backup management
Operations continuity management
Incident emulation
Information quality and compliance probing
Alerts monitoring
Events detection and analysis
Handling of incidents and near-incidents

GP-1
GP-2
GP-3
SSP-6
TSP-2
TSP-3
TSP-8
TSP-9
TSP-10
TSP-11
OSP-2
OSP-9
OSP-17
OSP-11
OSP-12
OSP-14
OSP-10
OSP-15
OSP-20
OSP-21
OSP-22
OSP-23
OSP-24

Table AV.
ISM3 (ISM3
consortium, 2007)

Capability
domain
Advanced security and
threat research

Table AVI.
ISF (Borrett et al.,
2013)

Domain
practices

Generate comprehensive knowledge of vulnerabilities and attack methodologies
Apply the comprehensive knowledge of vulnerabilities and attack methodologies
through effective protection technologies
People
Manage and extend enterprise identity context across security domains with
comprehensive identity intelligence
Data
Secure the privacy and integrity of the organisation’s trusted information assets
Applications
Reduce the cost of developing more secure applications
Infrastructure
Guard against sophisticated attacks with insight into users, content and
applications
Security intelligence and Optimise security with additional context, automation and integration
analytics

Capability
domain

Domain
practices

Preparation

Identify and assign personnel to speciﬁc risk management roles
Establish organisational risk management strategy and determine risk tolerance
Identify the business function processes the system is intended to support
Identify system security and privacy stakeholders for the entire life cycle
Identify assets that require protection
Identify information life cycle for systems that process personally identiﬁable
information
Conduct initial risk assessment of assets and continually perform and update the
risk assessment status
Deﬁne stakeholder protection, security and privacy requirements
Determine the placement of the system within the enterprise architecture
Establish and publish organisation-wide customised control proﬁles and baselines
Identify and publish organisation-wide common controls available for adoption by
other organisational systems
Prioritise organisational systems with same impact level
Develop and implement organisation-wide strategy for monitoring security and
privacy control effectiveness
Determine the system boundary
Identify security and privacy requirements allocated to the organisation and its
systems
Identify information types to be processed, stored and transmitted by the system
Categorise system and document security categorisation results as part of system
requirements
Describe the characteristics of the system
Register the system with the appropriate organisational project/programme
management ofﬁces
Select security and privacy controls for the system and document functional
descriptions of the planned controls
Supplement organisational continuous monitoring strategy as needed, at system
level
Review and approve security and privacy plans
Implement security and privacy controls speciﬁed in security and privacy plans or
other system documentation
Document changes to planned security and privacy control implementation and
establish conﬁguration baseline for the system
Develop, review and approve a plan to assess security and privacy controls
Assess the security and privacy controls in accordance with the assessment
procedures deﬁned in the security and privacy assessment plan
Prepare security and privacy assessment reports (issues, ﬁndings and
recommendations from security and privacy control assessments)
Conduct initial remediation actions on security and privacy controls based on
ﬁndings and recommendations of the security and privacy assessment reports
Prepare plan of action and milestones based on the ﬁndings and recommendations
of the security and privacy assessment reports excluding any remediation actions
taken
Assemble authorisation package with an executive summary and submit for
adjudication
Determine risk from the operation, or use provision of common controls and/or the
system
Identify and implement preferred course of action in response to determined risk
Determine if risk from the operation/use of system/provision or use of common
controls is acceptable
(continued)

Categorisation

Selection

Implementation

Assessment

Authorisation

Cybersecurity
framework

265

Table AVII.
NIST-RMF (Joint
task force, 2017)

ICS
27,2

266

Capability
domain

Monitoring

Table AVII.

Report authorisation decision and any weaknesses or deﬁciencies in security and
privacy controls
Monitor changes to the system and its operational environment
Assess security and privacy controls used
Respond to risks emanating from risk assessment activities, results of ongoing
monitoring activities and any other outstanding actions
Based on the results of the continuous monitoring process, update security and
privacy plans, assessment and milestones reports, and plans of action
Report the security and privacy status of the system continually and in accordance
with the organisational monitoring strategy
Continually review security and privacy status of the system to determine whether
risks remain acceptable
Implement system disposal strategy

Capability
domain

Domain
practices

Project management

Project planning
Project monitoring and control
Requirements management
Supplier agreement management
Integrated project management
Risk management
Requirements development
Technical solutions
Product integration
Validation
Veriﬁcation
Conﬁguration management
Decision analysis and resolution
Measurement and analysis
Process and product quality assurance
Organisational process deﬁnition
Organisational process focus
Organisational training

Engineering

Support

Table AVIII.
CMMI-Svc (Penn
et al., 2015)

Domain
practices

Process management

Capability
domain
Requirements management

Domain
practices

Resilience requirements development
Resilience requirements management
Asset management
Asset deﬁnition and management
Resilience establishment
Service continuity
Controls management
Resilient technical solution engineering
Asset resilience management
Environmental control
Knowledge and information management
People management
Technology management
External dependencies
Threat, incident, and access management Access management
Identity management
Incident management and control
Vulnerability analysis and resolution
Governance, risk and compliance
Compliance
Enterprise focus
Risk management
Supporting resilience
Communications
Financial resource management
Human resource management
Organisational training and awareness
Data collection and logging
Monitoring
Process management
Measurement and analysis
Organisational process deﬁnition
Organisational process focus

Discipline

Cybersecurity
framework

Engineering
management

267
Operations
management

Enterprise
management

Process management

Table AIX.
CERT-RMM
(Barbour and Caralli,
2010; Caralli et al.,
2016)

ICS
27,2

268

Table AX.
O-ISM3 (The open
group, 2017)

Domain
code

Capability
domain

Domain
practices

Practice
code

GP

General

SSP

Strategic management

TSP

Tactical management

OSP

Operational management

Knowledge management
ISMS and business audit
ISM design and evolution
Report to stakeholders
Coordination
Deﬁne division and duties rules
Allocate resources for information security
Report to strategic management
Manage allocated resources
Deﬁne security targets and objectives
Service level management
Security architecture
Personnel background checks
Personnel security
Security personnel training
Personnel disciplinary process
Security awareness
Insurance management
Information operations
Report to tactical management
Security procurement
Inventory management
Information systems IT managed domain change control
IT managed domain patching
IT managed domain clearing
IT managed domain hardening
Software development life cycle control
Security measures change control
Backup management
Access control
User registration
Physical environment protection management
Operations continuity management
Segmentation and ﬁltering management
Malware protection management
Internal technical audit
Incident emulation
Information quality and compliance assessment
Alerts monitoring
Internal events detection and analysis
Handling of incidents and near-incidents
Forensics
Enhanced reliability and availability management
Archiving management
External events detection and analysis

GP-1
GP-2
GP-3
SSP-1
SSP-2
SSP-4
SSP-6
TSP-1
TSP-2
TSP-3
TSP-4
TSP-6
TSP-7
TSP-8
TSP-9
TSP-10
TSP-11
TSP-13
TSP-14
OSP-1
OSP-2
OSP-3
OSP-4
OSP-5
OSP-6
OSP-7
OSP-8
OSP-9
OSP-10
OSP-11
OSP-12
OSP-14
OSP-15
OSP-16
OSP-17
OSP-19
OSP-20
OSP-21
OSP-22
OSP-23
OSP-24
OSP-25
OSP-26
OSP-27
OSP-28

Capability
domain
Principles, policies and
frameworks enabler

Domain
practices

Information security principles
Information security policy
Speciﬁc information security policies driven by the information
security function
Speciﬁc information security policies driven by other functions
within the enterprise
Processes enabler
Evaluate, direct and monitor
Align, plan and organise
Build, acquire and implement
Deliver, service and support
Monitor, evaluate and assess
Organisational structures
Chief information security ofﬁcer
enabler
Information security steering committee
Information security manager
Enterprise risk management committee
Information custodians/business owners
Culture, ethics and behaviour Behaviours
enabler
Leadership
Information enabler
Information security stakeholders template
Information security strategy
Information security budget
Information security plan
Policies
Information security requirements
Awareness material
Information security review reports
Information security dashboard
Services, infrastructure and Security architecture
applications enabler
Security awareness
Secure development
Security assessments
Adequately secured and conﬁgured systems, aligned with security
requirements and security architecture
User access and access rights in line with business requirements
Adequate protection against malware, external attacks and
intrusion attempts
Adequate incident response
Security testing
Monitoring and alert services for security-related events
People, skills and
Information security governance
competencies enabler
Information security strategy formulation
Information risk management
Information security architecture development
Information security operations
Information assessment, testing and compliance

Practice
code

Cybersecurity
framework

A.1
A.2
A.3
A.4

269

B.1
B.2
B.3
B.4
B.5
C.1
C.2
C.3
C.4
C.5
D.1
D.2
E.1
E.2
E.3
E.4
E.5
E.6
E.7
E.8
E.9
F.1
F.2
F.3
F.4
F.5
F.6
F.7
F.8
F.9
F.10
G.1
G.2
G.3
G.4
G.5
G.6

Table AXI.
COBIT 5 for
information security
(ISACA, 2012)

ICS
27,2

Capability domain

Domain practices

Securely provision

Risk management
Software development
Systems architecture
Technology research and development
Systems requirements planning
Test and evaluation
Systems development
Data administration
Knowledge management
Customer services and technical support
Network services
Systems administration
Systems analysis
Legal advice and advocacy
Training, education and awareness
Cybersecurity management
Strategic planning and policy
Executive cyber leadership
Programme/project management and acquisition
Cyber defence analysis
Cyber defence infrastructure support
Incident response
Vulnerability assessment and management
Threat analysis
Exploitation analysis
All-source analysis
Targets
Language analysis
Collection operations
Cyber operational planning
Cyber operations
Cyber investigations
Digital forensics

270
Operate and maintain

Oversee and govern

Protect and defend

Analyse

Table AXII.
NICE-CWF
(Newhouse et al.,
2017)

Collect and operate
Investigate

Capability
domain

Domain
practices

Process and analytics Conduct inventory of current workforce (e.g. skills, capabilities)
Perform supply and demand analysis
Conduct gap analysis on current and future workforce supply/demand of the
organisation
Develop and implement an action plan with a detailed timeline and phased
approach
Integrated governance Guideline materials for ongoing workforce review
structure
Panel to review the workforce planning process
Feedback mechanism to ensure timely course of correction in the planning process
Table AXIII.
Skilled practitioners Establish professional cadre of workforce planners
NICE-CMM (Dorville, and enabling
Integrate workforce planning systems, tools and capabilities to support workforce
2014)
technologies
planning activities

Capability domain

Domain practices

Identify

Asset management
Business environment
Governance
Risk assessment
Risk management strategy
Supply chain risk management
Access control
Awareness and training
Data security
Information protection processes and procedures
Maintenance
Protective technology
Security continuous monitoring
Detection process
Anomalies and events
Response planning
Communications
Analysis
Migration
Improvements
Recovery planning
Improvements
Communications

Protect

Detect
Respond

Recover

Capability domain

Domain practices

Project management

Project planning
Project monitoring and control
Requirements management
Supplier agreement management
Integrated project management
Risk management
Requirements development
Technical solutions
Product integration
Validation
Veriﬁcation
Conﬁguration management
Decision analysis and resolution
Measurement and analysis
Process and product quality assurance
Organisational process deﬁnition
Organisational process focus
Organisational training

Engineering

Support

Process management

Cybersecurity
framework

271

Table AXIV.
NIST-CF (NIST,
2017b)

Table AXV.
CMMI-Dev (Penn
et al., 2015)

ICS
27,2

Capability domain

Domain practices

Risk management

Establish cybersecurity risk management strategy
Manage cybersecurity risk
Management activities
Manage asset inventory
Manage asset conﬁguration
Manage changes to assets
Management activities
Establish and maintain identities
Control access
Management activities
Identify and respond to threats
Reduce cybersecurity vulnerabilities
Management activities
Perform logging
Perform monitoring
Establish and maintain common operating picture
Management activities
Share cybersecurity information
Management activities
Detect cybersecurity events
Escalate cybersecurity events and declare incidents
Respond to incidents and escalated cybersecurity events
Plan for continuity
Management activities
Identify dependencies
Manage dependency risks
Management activities
Assign cybersecurity responsibilities
Control workforce life cycle
Develop cybersecurity workforce
Increase cybersecurity awareness
Management activities
Establish cybersecurity programme strategy
Sponsor cybersecurity programme
Establish and maintain cybersecurity architecture
Perform secure software development
Management activities

Asset, change and conﬁguration management

272
Identity and access management
Threat and vulnerability management
Situational awareness

Information sharing and communications
Event and incident response, continuity of
operations

Supply chain and external dependencies
management
Workforce management

Table AXVI.
C2M2, ES-C2M2 and
ONG-C2M2 (US
department of
energy, 2014)

Cybersecurity programme management

Corresponding author
Sune Von Solms can be contacted at: svonsolms@uj.ac.za

For instructions on how to order reprints of this article, please visit our website:
www.emeraldgrouppublishing.com/licensing/reprints.htm
Or contact us for further details: permissions@emeraldinsight.com

